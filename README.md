# Redbus-Data-Scraping-with-Selenium-Dynamic-Filtering-using-Streamlit
## Introduction 
The 'Redbus Data Scraping and Filtering with Streamlit Application' aims to revolutionize the transportation industry by providing a comprehensive solution for collecting, analyzing, and visualizing bus travel data. By utilizing Selenium for web scraping, this project automates the extraction of detailed information from Redbus, including bus routes, schedules, prices, and seat availability. By streamlining data collection and providing powerful tools for data-driven decision-making, this project can significantly improve operational efficiency and strategic planning in the transportation industry
## Domain 
Transportation
## Skill-take:  
Selenium, Python, Pandas, MySQL,mysql-connector-python, Streamlit.
## Overview :
Selenium: Selenium is a tool used for automating web browsers. It is commonly used for web scraping, and extracting data from websites. Selenium allows you to simulate human interactions with a web page, such as clicking buttons, filling out forms, and navigating through pages, to collect the desired data...

Pandas: Use the powerful Pandas library to transform the dataset from CSV format into a structured data frame. Pandas help with data manipulation, cleaning, and preprocessing, ensuring data is ready for analysis.

MySQL: With the help of SQL to establish a connection to a SQL database, enabling seamless integration of the transformed dataset, and the data was efficiently inserted into relevant tables for storage and retrieval.

Streamlit: Developed an interactive web application using Streamlit, a user-friendly data visualization and analysis framework.

![Screenshot (72)](https://github.com/user-attachments/assets/955528e7-b0a3-47a0-a706-fa4b904bf7c2)

